   Ines Sombra: "Architectural Patterns of Resilient Distributed Systems"
   
   [Live captioning by Norma Miller @whitecoatcapxg]
   
   >> As you know I'm short, this is No. 1 and. This is No. 2: And I really like this, because every time I'm drunk I want to be taller than the people who are around me, so I'm having flashbacks. This is Architectural Patterns of Resilient Distributed Systems.  My name is Ines Sombra and I am an engineer at a company called fastly. This is how you get ahold of me. Hello to all of the organizers and speakers that are here. Hello to everybody who is watching this from home if you are watching from home, I highly recommend that you go and join your local chapter of ....
   So I work for fastly I don't know if you know what fastly is. It's a content delivery network and globally distributed network of servers. So we had a booth here, we shut it down so we can all be here, but real time is our thing so if you're interested ping us after the talk. Let's talk about what we're going to cover today. So he we're going to go on a journey together and first part we want to figure out why we should care about this thing called resiliency and then we're going to check what the literature tells us and what the industry tells you about it and mesh everything together into this big huge pile of conclusions.
   >> So I don't know how many of you have seen my talks before. If you haven't seen my talks before, this is my my obligatory disclosure slides. You may want to tweet it, but I'm going to speak really fast so fuck it, let's do it. Also wedding trivia, so I'm getting married in 20 days, yes. Whoo! And I kind of underestimated the amount of stress that you would go whenever you're about to get married and of you have to make a talk, so this talk has a lot more of me in it because I am unable to filter out the things I shouldn't say, so yeah, also apologies to Norma whom I'm going to torture through the iteration of this talk trying to see how fast she can closed caption this. So, yeah, why resilience? 
   [laughter]
   So a year ago -- did she say something?
   Yeah, yeah, good. So a year ago I became a distributer systems engineer. Before I used to dabble and I decided to make it official and see what it looked like from the engineer point of view and just actually do that. So I started my first day as a distributed systems engineer and I realized quickly that my entire perspective had changed and now I had to help construct the systems and help the systems stay up and that was a little that was a little different. So everything that I had read before and I thought I understood all of a sudden became that I thought it was obvious once I was in there and in the middle of it wasn't as off why us anymore. Everything changed and everything old became new and I had to go and read the old papers I read before with no context with much much more context. So I started wondering what are the things that I'm going to make to this particular application that it's gonna actually make it less robust and I noticed that for example when I interrupted one system I caused availability problems in another, basically means that just it shut it undo. So I knew that this was going to happen but I didn't think it was going to happen to me,a, so yeah, it happens to everybody, I guess. And then I also had an opportunity to start a new prototype and everything that I had read before, kind of like loomed over my head and it was a little paralyzing because I didn't know if the things that I was making at the moment were going to be the biggest pieces of shit that everybody has with me had seen or not so the key take away is copy patterns that are already there because they've already come up with them so that was a good initial thing. So let's talk about resilience. So for the sake of this talk I'm going to define the ability of a system to deep working a adapt whenever things that are expected don't happen.
   >> Fault tolerance, evolve ability scalability and failure isolation and complexity management. I can keep speak but not that fast. It's been a year of like churning and churning and this is what I wish I would have known when I joined a little bit and kind of like, OK, they're very humble points of view but I had to actually work to get here, so it's interesting, but -P at the end the day I think for me resiliency is what really matters so you can have a good product and if you have any platform to stand on it may even cost your business customers.
   So it matters and at least it matters to me, so whenever now I'm deciding a thing or I'm helping with something else, the first thing that is on my mind is resilience and everything else is well, my code may not be pretty and we may not be using a language that is super awesome, but resilience is now at the forefront of my mind. So I said that we had like -- I had like read some literature so I do a lot of literature and then there was three models that actually stuck with me and changed my perspective even more he so I'm going to go through them fairly quickly and we're going to carry on. So the first model that I picked is called harvest and yield. It's and oldy but goody and it was produced in 1999 by Amanda fox and erk Eric brewer and I read it recently again from this new life that you that I have now and it's still poignant and important because it formalizes a concept that we use no you to build distributive systems and also gives some ideas of strategy so we can enhance system availability in the preps of failure. Also it gives some patterns that we can use to make more resilient. So this paper has two concepts and us R. we're going to describe them again very quickly. We have yield that is a fraction of the successful and unsuccessful queries. Say for example you have something that sells shit and it's Christmas and people are trying to access your store and you have two minutes of down time entirely different than if your store goes down at 2 minutes on a Wednesday morning. So the paper tells that is we should focus on yield rather than up time. Harvest now, as a fraction of the complete results. I have this example has been quoted all through this conference, so it same coda emerges once and we compose great talks but all of it just go check that reference. So he tells us that we can have like this example where we have cute baby animals and the indexes are in different servers and I want to search for cute baby animals and my server B goes down but you can see now with one server gone I can have 66% of harvest I'm still going to like offer something that would be acceptable to me. I would say cute animals, there's bound to be babies there, so yeah, so again those two concepts are very important but what I want to emphasize is the strategies that the paper tells us. So the first strategy that they tell us is called probabilistic availability and this is deals with degradation of services under fault and they can tell us that we can even out the worst case and the average case scenario this is for example if I want to distribute my data randomly through all of my notes and one of my nodes goes down. It also tells us that we can replicate data that is high priority so we can control a little bit of our harvest so the likelihood of losing that if one Node dies is going to be likely. And also they tell us that we can use degrade result. It's based on client capability. This is for example I have my phone and I want to watch a video and my connection is not great and I get a lesser quality of video but it's still OK. The second strategy they tell us is composition orthogonal ability. They may or may not be tolerant to degradation but our entire operation can continue operating if those subsystems fail. Also this gives us the advantage of only having to worry about providing strong consistency for the subsystems that need it and I hope that I'm keeping at a good pace? Is this too fast or too slow? OK, so I'm being told that it's OK. Then we have leverage orthogonal mechanism and I care about security and I may learn like a library or something that does encryption and security for me but I don't have to build it or codify like a security thing in my application. So we have then the concepts and then we have the two strategies that the paper proposes us and but then the thing that made the most impact for me was that if your system favors a harvest or yield it's an outcome of the design, so in a way this was a thing that was like the most useful thing for me because they're basically the things that we have to pay attention to when we're there. So the next model that I had actually comes from health care industry and I really like this one as well, and they say, OK, but the systems tend to be always operating at the edge of failure. And that any system that we launch into the world and starts to gets used and is relied upon is going to become safety critical. So in this model, they have the world and the universe where we have three boundaries, the boundary in the pink is the accident boundary, then the economic failure boundary and the unacceptable workload boundary and the thing in blue is the operating point. So we have pressures that come from one set of boundaries, say for example we needed to make this more efficient and then it moves the operating point and then maybe say we have like, OK, reduced cost and then the operating point just goes and then at this point we have an incident because it crossed the accident boundary. So we really don't like to have an incident, we don't really want to have outage problems or resilience problems in our organization so we're like OK, we crack down and let's go and launch a safety campaign and the safety campaign moves the operating point back from the accident boundary so we do this over and over and at some point we realrize that maybe there's a little bit of a buffer between the accident boundary and us so we end up creating what is called a marginal boundary and we have this little thing that is our perceived or our empirical error margin. And the operating point is always in motion, it also moves, and then at some point we may or may not cross the accident boundary depending on how we are close to -- pending on our position to the marginal boundary. So say that we were to zoom into the accidental marginal boundary relationship. Then it's OK, like so we are really getting used to not having outages and then our operating point is an acceptable place, which is like like inside the marginal boundary. But it's like, OK, maybe one day accidentally we go over it and it's like oh, we freak out and oh, we should do the things the way that we how to do them and we go back into the marginal boundary where we consider it acceptable but you know what, like last time, weep didn't crash, so fuck it, let's go again and we're like, OK we didn't crash here either and maybe we go this way and maybe this way and we're going to get comfortable to this point where we're already close to the edge. We already know where the edge is but at this point we started living really close to it and what ends up happening is you end up defining a new marginal boundary so what you're going to fail on is not going to change but your closeness to the error is much much more, you're much closer to that. Obviously we have many examples of this this talk for example is like me right next to my accident boundary, like yeah, it's right there, so, yeah, so you can tell me, well, this is fine if I -- we're we still haven't crossed it, this is great.
   So yeah, maybe obviously we don't really want to do that as I told you I am trying to be at this point in my life, concerned about resilience so I would not condone this way of living. So OK. So what are the insights from the model that Cook tell us and this is again from the health care industry. They say in order to actually engineer something with resilience it requires a model of space that is adapted on mentoring, responding, adapting and learning. And also where the operating point actually is and what do we do under pressure. Actually the studies is the difference between hospitals with high mortality and low mortality rates is the way they respond to the incidents, like the accidents happen in both of them but the adaptability is much more fluid not kill people nicer or better than the other one. So yeah, don't kill people. So the thing that they tell us, too, is this resilience is also like focus on the operating community so from the harvest and yield we have design, from this one we have actually a case for why operations matter.
   So all right, how do they tell us that we should build the resilience in our system? They tell us that we should actually build support for continuous maintenance, that seems reasonable. Also that we should reveal the control of the systems for the operators and actually reveal the whole control because basically they may be the ones that are dealing with your system, we may agree or not agree on that one but the one thing that stuck with me is that your system ising going to moved and used in ways that you didn't intend. Period. That's going to happen. And also think about your configuration of interfaces.
   So that is the Cook model.
   So the next one I said give me a different perspective and he said sure, read this paper, read this paper and read this paper. So I'm not just going to call it the Borrill model. This guy of prolific of reading papers and then bombarding you with them, but they're very, very good. So in this case I'm going to take a little bit of a liberty and just not show my work but tell you the gist gist of what I got from all of those papers, too, because I read them. So they give us a different visualization for system complexity so on one side we have the probability of failure and the other side is the rank. The rank is to find the most probable to the least probable and also there's areas where there's least probable, no shall, most probable can address with traditional engineering, then we crossed the error boundary and ah, we shouldn't do this again and we put it into a play bock and then there's this area called UNK-UKN it means unknown, -P unknown so this is where you have the cascading or catastrophic failures so you don't know where they're going to come and the thing that my chart doesn't really display very well is that it goes on and eventually the area of this unnope is going to be as big as the others combined. Trust me on that one. I didn't have time to make it prettier than it is. So another thing they tell us is whenever we scale the areas under the curve start to change and we can trunk it a little bit by putting limitations in place but then we renormalize and then unk-unk gets bigger. So first we had design, then we have operations and now we know that maybe our attention should be split in three different places, where we we can have engineering and this other thing is going to come and get us and there's nothing we can do, so OK, these different things that we have in our world should require different strategies of attack. Or different mechanisms. So different methods should be to different studies in order to be concerned about them and what he mentioned would be cool is we have the Kingsbury on the other side and we have just the other on the other. So this is the embodiment of strategies and if you're building pa system imagine getting your report card from those two guys together and you leave the industry forever and start we go baskets or something. But OK, so we need different strategies and what are the strategies that we have, what are the tools that we have for each one of them, for example for classical engineering we have things like code standards, programming patterns, testing we should know the full system is the client, the code, the provisioning code and also maybe your operation should start mattering and we should have metrics and monitoring, you wait until you put the system into pronunciation and you're like ha, how do I see it? And also interesting with classical engineering is that basically we're striving for something that is a convergence to a good state so we want the system to be able to kill itself enough or not freak out enough to the point where it can just go and start behaving the way that we expect it. In reactive operations we have hazard inventories, redundancies, feature flags and dark deploys, run books and docs. And canaries, things like that. In the unknown unknown we can't predict, we weren't able to see, because if we were able to see we would have already engineered for it but the goal of these things is to build a failure domain independence. So it won't take down your entire application.  So we can map it down to the first paper and then we see this ability to like respond to failures is keeps popping up again and again. Which means that maybe my topic is correctly, so yay. So from the Borrill method, the thing that I took away from is thinking about resilience is that we have to use more than one discipline in order to attack it properly. One discipline is insufficient, and this is what we take away from the third literature model that I prepared for you. But also this kind of sucks, right because we have to protect ourselves against three different fronts now. It's kind of like a bummer, as well.
   So I promised you wedding trivia now. So I wonder if you know what this is. This is a wedding cake, right? It's like wrong, it's not a wedding cake. There's a section onetsy where you can get fake wedding cakes. It's basically styrofoam with some sort of sugar thing on top that and for $10 more you can actually have them carve out a little piece and then you eat it and pretend you have really good cake and then you er is of your guests really cheap cake. So also, fuck the wedding industry is it's the worst so. If you were wondering how much it costs you to have a 20 to 35 minute ceremony in San Francisco you're looking at $600 to $1,000. I don't have an officiant yet. I kind of have one in the works, about you who knows, so not stressed about that one either.
   So OK, let's talk about resilience in industry so it wouldn't be a distributed system talk if we didn't quote the distributed systems poster child and here's my Netflix things so I do want to leave some thoughts so my Netflix with sparkles, so OK, so what did they pull for like the Netflix best literature, so they had this blog post a while ago that they talk about their API and how they're doing fault isolation at the A API level and we find out that the API as we probably know is probably more vulnerable to any failures, or latency. We probably know this, I know this but then I was causing availability issues in the API and I was like why the fuck isn't this thing staying up? So you need some context. So they say in their system without any fault tolerance that this could reresult in about two hours of downtime per month so not great, right and the way that they solved this is they actually used client libraries and they. So here for example in this picture you have a request and spanning out the things to the dependencies and this is how they looked after they architected it. They started using ha depressive timeouts, retries or semaphores. I told you just now that they separated into dependency pools and since they had time outs they basically wanted to prevent these threads from locking and consuming all of the resources. The interesting thing is that they talk about circuit breakers, as well, and it means that basically say for example they notice over 50% error rate in a span of 10 second, then they will back off and try to relieve pressure and only try start sending things back to the people they were talking about after the health check came back OK.
   All right. Good, so that is Netflix. We can move on to the other one, because instead of having one poster child, I want to have two, yeah. OK, this is Google and they already found their logo and if so it's skinnier and if you're paying for a wedding you have to do that too.
   I think the paper that stuck with me was the chubby paper and the chubby describes the lock-in system that they have. The reason that this paper is really nice is because it describes their thought process and what it looks like whenever you're building something for people that are in your side of the fans so you can't really call stupid but they're kind of there so you kind of want to go and enable them, as well. So the key insights for the Chubby paper for me. Is the Netflix people umessed the library and the particular blog posts that they have mentioned and in this is ca the people from Google decided to go and build a service and also they did the client library and they had control over both of those two things. This is probably the thing that is say the slowest I've said, right? So then a storage, they also did like support for small data files and they restricted the operations you could do with the files and you couldn't pull something that's huge, they just very, very carefully delineated what you could do and what you couldn't do and the paper is kind of a bummer, as well, because they said that they found that their engineers don't plan for availability, consensus, primary emexes, failures, their own bugs, operable or the future. So like, fuck, everything is awful. So fine, like, wah, yeah. All right, so goods more key insights since we're here and already depressed. You can actually dedicate somest effort into making them more failure tolerant and making sure they're resistant and scalable and making sure you can consume this thing that has been well architected and constructed for you and also found out what they restricted what you can do because they had one thing and to do it very, very well and also like OK, fine, like the consumers of your service are like basically part of your unk-unk scenarios, they predicted that they themselves knew that people started using it in ways they never expected. But I think nobody can really predict what the future is going to be like, so, yeah, so, many, so OK, so like we see the two poster Childs and the reason I became interested in is actually because my con. So I was just going around fastly and seeing how do we do this and areas especially areas of the systems team it, I mean there's many other teams. And what we can leverage, what can I what could actually help me in this cognitive journey that I'm in and it's funny because like the old school web performance people were telling me that they themselves noticed that it's changed since then and they noticed that in applications that were on my side of the fence, as well so I'm going to talk about two systems that we publicly talked about and talks about it online so I will reference you to the talks later and if you're interested in checking it out a little bit more. So the first system is our system called powder horn. I'm just going to Tuesday truce for Tyler and Bruce together. This talk was given in Barcelona last year and they talked about the evolution of our purchasing system from V1 to V3 and you walk you through all the design decisions and the assumptions that were there in the beginning and everything that like is going to screw us up toward the end and then at the end of it they leverage bimodal multi-cast to provide extremely fast purging speeds so if you're interested in what is the design concerns and system evolution like I was, it will give you more insight into how people construct these things.
   Who knows how many Vs we would have right now if we hadn't run through this piece of research and also, like it also tells us that planning for resilience is hard. As work expanded we went from the engineering side of the problem in the graph and to the unk-unk very, very quickly so new problems cropped up and this is a problem I have then with unk-unk. The things that are problematic with an an unk are things that you can't see. Because if I didn't see it because my universe was undeveloped, but say for somebody that was more experienced that would have been something very obvious for them so I don't like the fact that this is a personal perspective things but I am cognizant that it exists and so maybe this is an argument why you should have different cognitive diversity in your team because my perspective is only one perspective in this realm of shit that could come and murder am your application.
   So how do things look like closer to the internet and this is my coworker Joao, he's a very cheerful personal and those are the things that you're going to hear him say. But his team is hiring, too, but this is Joao looking very, very suave and. But let's describe a simplification of our point of per specstives are, so our faults so we have a ship with a monster and a PoP with this little red line there and traffic comps and at some points a host will fail and you have to be able to go to a host but take that node out and bring it back in. So we use this thing called SRE con15, multi-past it recalculates the tables whenever I piece change so we didn't want node to go away and then traffic of B to move to the position of node A so that was a problem we ran into so we ended up doing something very clever. Ended up making the system called failed V that allows us to fail and recover hosts. So instead of being on the host this is apparently the replacement for a is is tem called. You have no context on that, but if you have context on you know what the system is doing. So yeah basically what we do is we make fake IP addresses we map them to Mac addresses and whenever a node fails the IP address is still there but we switch it to a Mac address. So if you're interested in this, Joao has a much better explanation. And for me to inform this thing how it's done at the edge is basically leveraging things the same way we do at the core, right? So, all right, but you may say wait a minute. We have a myriad of systems then why were you where were you when you started investigating this. What I learned OK in every organization you're going to have a lot of systems and then they all have different stages of resolution. So varnish powder horn and Faild, but some applications still have availability issues because I told you this. So why is that? This is a moment I take another second and I drink a little water to make sure I don't pick up speed again, but remember where I was. OK. So why do we have these hinges? So what are the things that we failed to consider whenever we run into this problems. So these are like the patterns that I picked up or the patterns that I distilled that seemed to be the ones that are more relevant to me. So redundancies matter so we have limited resources, execution path checks, replication of data, replay of messages, anti-entropy, all these things, they help us with resilience. Also gossip and epidemic protocols is another examples of redundancies and if we're talking about redundancies, this is something that I learned this year, as well, that capacity planning matters. Redundancy is something of re, sos, but yes, it's surplus, but you need to be able to again increase, put the boundary of failure between one area it could get and just make sure that your failure domain doesn't overlap to other systems. If you can read what the bubble says, optimizations can make your systemlies resilient. So maybe you wanted to make it a little bit cheaper or not replicated as much as you know you should do or save money on a node that has and you put two nodes or like 4, it's not great. So another thing that we've learned then we said operating operations matter and we're kind of unaware or we forget are where the error boundary is. We've auld pushed applications to production and then like, OK, can you really guess where your first bottleneck is going to come from? Like I don't know, hopefully you do but I would say if you tell me that you do know it I would ask you to show me your work because maybe I think you're full of shit. So another thing that's interesting is complexity of operations makes a system less resilient and more incident prone. If it's too painful to operate eventually people with going to cut worners and this sacrifices the resilience of your system as a whole.
   >> This is something that comes in design, as well, so also just the biggest cost of security breaches is human error, so yeah, that's great. We're all great. Another thing that I learned, not all complexity is bad. So some other research talk about the number of complexity and the number of parts in airplanes and how it's considered a good thing whenever complexity is there to increase safety so right now we have cars and airplanes that are significantly much more complex than we had a few years ago but they're also very, very much safer and again, I mentioned this before, but added resilience it comes at the cost of other desired goals, so you should really figure out which one is your goal because if you want to run something cheap then you really shouldn't expect something that would be super resilient and also complexity is unavoidable so yay, so we tend to build things that are highly structured communications and control systems that create barriers. So all we're trying to do is make sure that those barriers exist and we should actually leverage and rely on engineering best practices, resiliency and testing are correlated, you should test your system. Also you should put versioning on everything, you should version your APIs, the formats and providing upgrades and evolvability of systems is still tricky. You examine actually flip one versus the other that would be much more, it would increase your operational happiness and I think this this also it's kind of shitty because we've seen all of this we're supposed to put all of these things in practice and we're still prototyping things in a way that I was when I was just making that little system if I wasn't sure that my system had any chance of making it in production. So like I don't know, I haven't found of a better way to think about -P prototyping. Jao mentioned in her talk that even mentioning a P checklist of borrowing from airplanes. I found one and it's listed in the references. And that was nice, but it's still by no means comprehensive, right? We prioritize systems like shit, right, and it happens. There's way too many fronts to attack and when I'm in the middle of it it's hard enough to get something here and then I have to worry about everything else so I think that there's something there that I don't really know how to reconcile. So we went through a whole journey and I have like five minutes to wrap it up, I think four. So what we've seen? We've seen resilience matters or at least it matters to me and I think it's like basically why we're doing what we're doing, which is why are things up. And things continue to be running. We've seen things in literature that say operations are important and also there's things that we're never going to be able to protect against, and we've seen some samples from like some implementations of these things in industry, as well, so everything that we've learned before gets hopefully connected in what we're seeing in industry, as well. So if you have been asleep through the entire talk I have a TLDR for you that kind of like meshes everything together. So say say then it was me like a year ago when I was trying to look at these things fresh. While in design are we favoring harvest or yield? I mean that is a design concern. So like if we're not coming a design, we're eventually not going to have it to dwell on. So we can leverage orthog onality and so on. Maybe in engineers don't rely and that was an orthogonal way to actually get those member elections and have those member elections. Do we have enough redundancies in place? What is the load you can ict is? Have we like given enough breathing room? Have we given it enough padding? Are we resilient to our dependencies, what if one of our dependencies fails? Are we favoring harvest or yield so you should know which one your business favors and also that theory matters. So you can continue reinventing the same thing and then just make mistakes and then again the unk-unk is a problem of perspective so if my perspective is false maybe somebody else who is researching this has a better perspective than mine. Operable, can people do the job with the thing that I provide to them. also the interesting one is do I want to be on call for this? I know you know how to operate it, but do you really want to be on call for this so that is a good one and also I think we should raping your services based on what can be dropped, killed and deferred and that is also listed in the references but it's very important because whenever an incident happens, it informs your operational activities and OK, do we have more monitoring and alerting in place? Then we have this again this thing of unk-unk and I think that again, it's like yes, matter of perspective, I can't cover absolutely everything but I think it also stresses diligence on the other two because it's a way that we can actually survive it whenever it comes and have we done everything we can? And if we think that we've done everything we can, Camille was like you should meditate in the flames of the tires, I am much more a proponent of human sacrifices and abandoning hope, so I think one or the other, maybe you have interns, it's like, it requires blood, so.
   [laughter]
   So yes, you so you can choose to that. I mean I think leadership styles. Yeah.
   [laughter]
   I like the meditation bit whenever I'm on the engineer side, so well, again while in design a little bit more practical. We should test our dependency failures. Code reviews are not the same thing as tests and this is covered in the Chubby paper. The Chubby team got bit by people leveraging the system in ways they didn't want to, also you should distrust client behavior even if they're internal. So we're like at the edge. So there was a talk at velocity this year by one of the Google managers and she says it's much more likely to do them themselves so I'm paraphrasing her. And also you should check anything that you write to disk, so a friend of ours told us he works at Cassandra and memory somehow flipped and the membership information and know that they didn't know before and all of a sudden it started talking to it. So you should do like, OK, things like error handlers, circuit break-ins, back pressure, leases, all these things are here to help you and when it comes to probability, any automation shortcut that you take while you're in a rush is going to come back to haunt you and by haunt you I mean something else, so I'm trying to clean up my language here, but so also like I've noticed this thing, too, that it's really stability like sometimes it's often tied to how stable your system is, so if you don't really have ironed out your release process then you're even adding more on these pile of things that are going to come and get you. And also interesting that I learned this year all of this I have very humble opinions like if you have an alert you should link to something that is actionable to it because you're being kind to your operators. Whoever a going to be on call and whyets this alert and needs to be able to react to it and if you don't do it you're basically signing up to be the person to be woken up because nobody else can handle your application.
   >> Some standardization in interfaces is a good thing. So if you have a system that gets and one is just config file ... This is my last slide and I also promised you a rantifesto.  we can't recover from lack of design. Not minding harvest or yield means we sign up for a redesign of our system the moment we finish it. And also if you don't have a service that's available in your company then basically you're building something that you know from the get-go is not going to be good. So I think this was what we maybe missed on some of the systems that I had that was encountering problems with and I think maybe as a company we're going to have to start making a choice. Maybe we're getting to a point where we're smalls, we're not as big as Google or Netflix but at some point we're starting to think about maybe we should put a service behind this or we should provide pa library and I think when you're small that tradeoff is always use a library or you justiel so that is interesting. I would like to thank the people that helped me they're all in this one and hi I run my system at the very edge and I prepare a repo for you where you can actually open up a request or say hi or whatever if you have any questions and all of the things that I mentioned in the talk and the extra references and the extra papers are listed there so thank you so much. Hopefully it wasn't too bad, Norma, and yeah, this is how short I am. Yeah.
   >> All right, guys. Whoo!
   [laughter]
   ... ...
   [applause]
