   Morgan Marquis-Boire: "Security For Humans: Privacy and Coercion Resistant Design"
   [Live captioning by Norma Miller @whitecoatcapxg]
   
   >> Alex: Before we get to our final keynote speaker today, which is going to be awesome, thanks so much to all the sponsors, again it would not be financially viable to do it without you and I thank all of you for doing that and helping us out. Thanks a huge thanks to the Peabody staff, they're amazing, you guys don't know everything that they do, but they're top notch.
   [applause]
   Cheer cheers.
   [applause]
   Thanks again to all the organizers, Ryan, Mario, Nick and Bridget, again they make my job easy here by doing all the hard work so I can focus on sort of coalescing things. Thanks to Norma, of course, doing the captions here. 
   [applause]
   Extra margarita for Norma tonight. And thanks to the video guys: Tim and all the crew who already got some videos up last night, and they'll probably all be up by early next week, so you can see the ones that you didn't get to catch.
   [applause]
   So one thing that I think it's important for us to realize is that we're software developers, and you may not have noticed but we're kind of taking over running this whole place. The world, that is. And that means that we have great opportunities. That means we have -- we actually have responsibilities, and so last night's talk was about that a little bit, and there are parts of last night's talk that I think will tie in very tightly to tonight's talk. If you recall the slide where Idalin talked about the ways that she was being shut down out of different communication technologies, that in particular I think will connect pretty well with some things that our speaker has to say tonight. And he's going to talk a lot about his work so I'm not really going to say too much about that. And I'm let him talk about that. But it is my great pleasure to introduce Morgan Marquis-Boire.
   [applause]
   >> Can everyone hear me? OK, that's great. Yeah, and thanks for that introduction, Alex, it's an honor to be the closing talk at the Strangeloop. The talks that I've seen here have been of ridiculously high quality and I'm not a jaded-enough shill that I say that to every conference I go to. In fact, I've never actually said that. So no, it's been really good. This talk is Security For Humans. Because I'm a security engineer, I'm actually not very good with humans so I think this is what a human looks like but I'm not really sure. I'm going to talk about privacy and coercion resistant design, I'm going to talk about a bunch of other stuff, as well. When I actually say privacy I am actually going to use it this in an exceptionally generalized term. I don't particularly want to get into the weeds on that although I do like these sorts of conversations and will be happy to have it the a the bar at the double tree later. So as I mentioned my name is Morgan Marquis-Boire, I split my time these days largely between security, human rights research, and journalism. My day job is being the director of security at First Look Media. I used to be a penetration tester. I had four or five years where I had a lot of fun breaking into power plants and that sort of thing. I spent six years at Google security being a security engineer, and I'm very enthused about the fact that I was one of the founders of the kiwiCON conference in New Zealand. So First Look Media is a completely new media enterprise endeavor. You've probably not heard of that name, but you've heard of these two people. One of them is Laura Poitrus, these are two of the journalists were given documents by this man, Edward Snowden. 
   [applause]
   Yeah, I think he's pretty cool, too.
   And yeah, so they were given a trove of documents pertaining to the activities of the GCSQ and the GSA and so in my day job I have to look after a bunch of unruly journalists and I'm going to talk a little bit about what I'm doing in the last 18 months but probably in vagaries for reasons that you'll understand. I also do a bunch of research and have done for a number of years with the citizens university out of Toronto. I also advise Amnesty International and Human Rights Watch and that type of things the potential human rights impact of emerging technologies and so forth.
   >> What am I talking about today. This particular crowd is really good at systems thinking, resilience in big systems, failure modes in big systems and in fact the previous talk was fantastic and it also was really funny so I enjoyed it a lot but I think this crowd thinks of systems failure and resilience in a very specific way and I've been thinking about this problem for a really long time in a slightly different way so I have to start with an admission. I was one of those kids who was really, really into the internet and I thought that the internet would save the world because I actually got to see it kind of happen, right? So bear in mind that like, you know, I'm an academic brat, and so, you know, my first experience with the internet was when my parents got e-mail at the university and would be able to send emails to other academics around the world. And, you know, I got -- I remember getting it at home and thinking that this amazing piece of technology would actually enable, you know, untold and unprecedented premium of expression which would naturally be sort of a liberation technology and issue in this global era of peace and goodwill towards everybody which isn't entirely what happened, you know, but it was kind of a 90s dream, you know, and it still lives on in a little part of my heart.  I try to keep that fire alive because of course what we got was a little bit more like this. Which is sort of unfortunate, right, and I think what happened was that much like a lot of technology early on it sort of benefited the early athe fast, the nimble, the technologist. But as guys will be aware technology is a power amplifier and that means that when forces of institutional power really got hold of the internet they were like oh, yeah, we can do all sorts of interesting things with this.
   So I'm going to talk about coercion resistant design and sort of the designing for the inevitability of what will happen to sort of the success of your endeavor, but I did this thing earlier where yesterday and today I've actually been talking to attendees, and I said, you know what would you like me to talk about if I was going to talk about anything you wanted? Like assume just one time only I'm a jukebox and I'll take requests and I had people ask all sorts of things, oh, you know I'd like you to talk about the targeted activists or surveillance and Snowden and all these types of things and I actually realized that a lot of these -- were questions I'd sort of had before and spoke to really human problems that really frustrated me because occasionally I can be a really impatient guy. But so what I'm going to do is talk a little bit about threat modeling and sort of a taxonomy of attackers and actors that kind of inhabit my world that I've studied over the last, you know, 6 to 10 years or something.
   And a lot of these cases have involved very real people. I'm sort of going to talk about this and I guess how we can try to design against these problem.
   So this isn't my usual crowd, so I wanted to ask some questions. Everybody here knows what, you know exploits are? Can I get a show of hands? This is good, like if I start talking about memory corruption heat sprays? Right, so this is good. So I worked with at Google for 6 years and I was on the team in Google who did incident response when we were hacked by China and this was sort of an interesting time. This is back in late 2009, early 2010 and what happened was that this kind of led to a lot of -- a lot of chest-beating you know? It was kind of like, oh, shame on you China how could you hack Google. This is really bad. And then of course we discovered that China hadn't just hacked Google, China had hacked lots of Silicon Valley and all sorts of other things besides and then as things progressed on we discovered that it wasn't just China but actually that all the nation states were hacking pretty much everything all the time. In fact if you had interesting data, the question isn't if someone will come for it, it's how many people will come for it and it's not actually all nation states. All nation states generally wish they were it's generally weighted to countries that have universities and mass programs and so on and so this takes us back 6 years and I was doing incident response and forensics and then there was this kind of wave of revolutionary activity across the Arab world.
   And you know I've been watching it on the news like many people. And I had friends called freedom botherrers, do-gooders, those sort of people and they ended up messaging me and saying hey, Morgan, you know, we think we're seeing malware that's actually sort of targeting, you know, activists, human rights researchers and sort of journalists in Syria. This sounds like your sort of thing and I was like, yeah, OK, could you have a look at it for us and so I started analyzing this malware as it came in and some of this was actually pretty grim. This guy's name is Taymour Karim and he was arrested by the Syrian authorities, he was tortured, he says he thought he would never see daylight again, but the thing he said that stuck with me was he said my computer was arrested before I was and they had transcripts of all his Skype chats. They'd been logging his key strokes, looking at his emails, that type of thing.
   And I spent years like literally years, tracking these sort of operations in Syria. The guy's face you see there, his name is Borin Gallion. He's a lecture at the Sorbonne in Paris. I mean there was things that they would do, like they hacked his Facebook page and by they, I you know, there's a kind of in my end of the woods attribution is tricky and so I would generally use the term pro-Syrian government actors perhaps, sort of a nation state sponsored hacking attempts. Sort of his Facebook was compromised and links to malware were spread through his Facebook to sort of various interesting followers and associates of his and this is just an example, this sort of campaign continued for years and actually sort of continues to the current day. I published a variety of maybe like 13 or 14 pieces on this, with the EFF and with citizen lab, and in late 2012, I was contacted by Bahrain Watch and this is a group that monitors the sale of arms internationally to Bahrain. It is not very popular with the Bahrain government. This woman's name is Ala' S. She's now what I call Finfisher patient zero. I'm not sure how much you know about the scene but as the desire for internet surveillance capability has increased with the move of people using the internet as a default digital commons for our world there's been a booming commercial market for offensive software. Finfisher was one of the first companies to come to light as providing the stuff commercially. They're a company based out of Munich. And what happened was during the Arab Spring in Egypt, the doors of the state surveillance secret police were kicked down and ransacked, and people found all of these documents regarding the sale of this software and these were published and so this sort of gained notoriety but no one had actually seen the software when 92, 93 sort of the birth of the virus scene and you've got John McAfee screaming that a virus is going to destroy the internet and nothing happens and so I was actually interest very, very interested in what commercial malware actually written by, you know, they have an office, you know where it is, this is a large group of people, they have a group of employees that they presumably pay reasonably, I was interested in what they look like. And she was actually the first person that was ever found to be targeted about it and so I helped her analyze it, it was actually sort of interesting. They used this interesting polymorphic packer with several different plates to sort of obfuscate and someone to frustrate someone trying to do reverse engineering of the code. I mean it was all right. I think it cost something like 300,000 Euros. Don't get any ideas I would be really pissed if that was the take away of this talk. You know, so after I did that, sort of you know, released a paper on that together with Bill Marzcak who was a member of Bahrain Watch other people started getting in contact with me and I started following this scene more closely. In Morocco a citizen journalist movement named Mamfakinch, they were targeted using another piece of malware, they were actually sent, being a journalist like someone actually went to their contact us page, sent them a small message which said this is really sensitive material, I need to stay out of this, but you know, you need to have a look at this and it was a link to a document named scandal.doc which happened to be a Word document containing an exploit which then installed this commercial surveillance software. So these are all cases that I actually ended up working. This man is Ahmed man so, 0r, he was also being -- he got released from jail, I think he served two years or something, and he -- his political views didn't change but unfortunately the political views of the establishment in Abu Dhabi didn't change, either, so it meant as he continued to give pro-democracy lectures, he found that he was being tracked physically and assaulted and he would go to give these talks and he would be physically beaten and he had no idea how this was actually happening, how they were finding him.  He ended up getting in touch with me subsequent to the work I'd done for Bahrain Watch and it turned out that he actually also had a commercial surveillance implant installed on his machine and they were reading his e-mails and using it to track his location, now, the software was with a group called Hacking Team. I think the you actually the name came first and the product came second because normally you do it the other way around, the product is called remote control system which is really boring and bland, right so if they'd applied that to naming their company it might have worked out better for them. Essentially they're an Italian company that sells what's essentially software, back-doors implants, malware for lawful interception. I don't really like the word abuse the recalled word itself implies it's fine because it's got the word lawful in it. But fundamentally it's governmental interception. You know, you record what people are doing their their webcams, monitor ambient sound around their computers, read their emails, see who they're communicating with and that kind of thing. As part of this work I did the first analysis, together with bill Marcsak of a suite of malware for mobile phones there's a paper I called the smartphone who loved me. It doesn't contain this cute picture of the Android getting wasted, but the spyware provides all the stuff that you imagine you might want for the purposes of espionage surveillance or tracking, right? it intercepts calls, tracks people's GPS location, obviously allows you to read people's messages so on and so forth. The bit that actually freaked me out was the invisible microphone facility. It's actually called spy call when you disassemble a code, right, it's actually called there's a function called spy call. And so what that does is it takes over the hardware of the phone and instantiates an outbound call to a remote number so someone just hears all the ambient audio around your phone and of course, you know, phone's still dark and that type of thing. If there's an incoming call what it does is returns control of the hardware to the phone processers, you know, lights go on, phone vibrates and that sort of thing and it places the outbound call on call waiting and of course you know, you when you finish your call spy phone kicks in again and they start listening to you and of course I'm sitting there and I've got a decompiler open and a disassembler and I'm looking at my phone and it's kind of this sort of thing where I'm like -- and I start thinking about putting it in the fridge, right? I've become one of those people, like damn it.
   [laughter]
   You know, which I think speaks a lot to the relationship that we have with these devices that we carry everywhere, right? It's kind of it's the first thing I look at in the morning and the last thing I look at before I go to bed and half of Americans between the ages of 15 and 30 check Facebook on their iPhones the first thing they do in the morning and you have this odd trust relationship with something that you carry around with you all the time. As discussed in the previous talk I'm going to show none I manufacture working on this but I wrote a paper for the University of Toronto and you can look it up and there's hashes and domains and IPs and all those sorts of things so you can look at it there. But these conferences much like this one where you can go and actually talk to these vendors, this one is commonly known as the wiretapper's ball. And you know, there's one in DC, you know, they have it around the world, you a long and surveillance vendors show their wares, this is not the only brand of this conference there are others where you can go to purchase your surveillance software together with your gold-plated Uzi or whatever dictator fineware. Around that time I actually started tracking in addition to this bespoke targeted surveillance I started targeting the usage of hardware and software solutions that provided I guess what you would describe as massive surveillance and also mass censorship. One of these companies called Blue Coat. They provide software which can be used rather benignly, like it's used to prevent the viewing of pornography in libraries, say. I talked to a Blue Coat salesman at a conference and I I was like whoa, how big do these scale in you must really hit some bend with these things and he's like oh, no, we can do entire countries? Oh, really? Entire countries? That must be really handy? And oh, no, and of course there's sort of issues with that, right? And so you know, myself and a couple of fellows a couple of years ago Colin Anderson primarily did a bunch of scanning of the whole internet looking for these devices and we came up with a kind of a criteria, I guess for deciding whether or not we cared about it. For instance if you found it on a private network, so this is a corporate network, right, then it's like well, these networks belong to whoever this is assigned to so technically I guess they can do whatever they want with it and also people sign some kind of agreement, however draconian it is, and they can do whatever they want with it. These are the black areas. The blue area is when we found them on public ISP provider and government networks and so we did a bunch of this and of course we found it in a couple of areas that are just simply contraindicated like Syria. Now, that's actually just flat-up illegal for a US country to sell stuff to Syria and Blue Coat was filing $2.8 million. This wasn't the first work on the skullduggery of Blue Coat. There was a group called teleconnics about a year later we followed it up and actually found that not only in Syria but also in Sudan and Iran was this gear being sold so I mean this is an American company who is selling filtering, monitoring and censor apparatus to customers with human rights records that you might think are not great. I mean that sort of part can actually get contentious, right, in that I sort of get other people sort of respond to me, well, the US runs gulaga, Guantanamo Bay and things like that, well, that's true. But at least the US complies with human rights ... I kind of continued to be contacted by people who felt that they may have been victims of sort of state sponsored aggression digitally. There was a woman in LA who ran the largest political blog and her WordPress got hacked and she got logged out of her blog and my first thought was actually, I don't know if this really looks state sponsored, I mean how petty can a state be? Answer is very. Because at the time I couldn't really figure it out. You know she'd actually done a lot of sort of restorative work, had people help her try and get the blog back and the trail was greasy and kind of cold but I sort of did what I could and I kept the data and then you know, I ended up sort of talking to, you know, more and more people about sort Vietnam ease government's surveillance and I encountered more and more people who felt they were victims and this blew up when a guy who was the author of this article as a journalist who is stationed on the ground in han Hanoi and he received a document that promised to be the breakdown processes of Vietnam and this actually proved to be targeted malware to attack his system. And there was actually the same kind found on the woman who ran the blog out of LA. This was the same as malware that had been used to target a Vietnamese constitutional law professor who wrote extensively for proposed changes for resume of law for Vietnam. And what we ended up seeing was kind of a pattern of basically every politically active Vietnamese. Not military or government installations, not large corps rats, but actually individuals, activists, journalists, that type of thing and this was the last piece of work that I did publicly before I left Google which was a study which ended up showing that I think 21 out of 25 of the world's top news organizations had been targeted by state sponsored attackers.
   I then moved to, working for First Look Media where I released some work on the targeted malware used by the five I's or the UK, Australia, Canada, New Zealand and the US. They used this to compromise the European Parliament. They hacked and this was actual in kind of an implant that had been written by the five Is, by hacking Belgacom,.
   After that I worked on Babar was amusingly what we ended up calling the French government's. .. -- this linked to a whole bunch of other stuff that was found in Iran and Syria. Recently at Black Hat I released something on I guess a suite or I guess in this case it's kind of almost like archeology, because this goes back to 2002. And so I don't know how many of you guys remember like the new executable format. Like 16-bit windows and stuff this malware targeted those systems and this is kind of archeology and this looks like Israel.
   Alberto nisman, he was a lawyer and he was just about to diet the president of Argentina and then he was found mysteriously dead in his apartment a few days before that apparently from suicide by gunshot to the head, no powder burns on his hands, everything looks very suspicious and as it turns out there was malware on his phone. So I ended up looking into this and found that this actually tracked to a whole campaign of spying in Latin America, including against other high profile, you know, investigative journalists and allegedly although I was unable to prove this, ended up targeting the president's son, as well.
   So I've had an interesting time doing this type of work over the last few years. This guy is the PR flack for Hacking Team, who was one of the companies I mentioned before who writes sort of commercial tools for espionage. He doesn't like me very much.
   One of the things he sort of said to a reporter was he was kind of like, hey, you know one person's activist is another person's terrorist. They sent this to my bosses where they called me a tireless wolf cryer on the issue of privacy and then I think they argued that I was helping pedophiles and criminals with my work which seemed a little by harsh. See, that laugh is he can actually what I did was hacking teams themselves got hacked earlier this year and their e-mail spool got dumped and inside this e-mail spool because in this age of self-Googling, so I looked myself up and I'm sure it's not personal but Iowas mentioned 117 times in their e-mail archive, my Twitter pseudonym was mentioned 29 times and I'm at headhunter an Twitter which got 15 mentions which clearly I'm not big enough on Twitter, but when things got even weirder was that they actually took photographs of me and recorded me. So this is me giving a talk actually not dissimilar to this one, in fact it does use some of the same material that that talk that I gave and this is photos that they took of me. This was actually found in the home directory of one of the Hacking Team guys and I got some mail from someone hey, have you looked for yourself, did you see this stuff where they surveilled you? And I was like wait, what? Which I have to admit came as a little surprise to me but that is not actually the weirdest thing that came out of this work. This is the weirdest thing. That's why I said before, like none of you guys get any weird ideas. Because we had a meeting with Eduardo so they use code names so with a group from. Phoebe, so if we go mnemonically, FBI. So phoebe, whoever that might be, they met with and it turns out that this meeting was because of a piece that I wrote. I wrote a piece called police story about hacking teams mobile implants and they see if anything got came out of the citizen lab articles it's that it brought them to contact us to see if it was true, it was more than they expected, thank you, citizen lab. And I was kind of like, what? Am I just doing free QA for these people like you reverse the software and the obfuscation is kind of it's like really, anyway, so FBI looks at it and is like, huh independently verifies their promotional materials, that's come. I don't know.
   So yeah, anyway, this stuff is kind of grim so I like to stick kittens randomly in my slides.
   But anyway, I mean t the thing is that you know, this -- I mean in some ways it's an interesting crowd today because there are a lot of skilled software developers and they're also writing this software and this market is only increasing, right? And it's -- we've seen kind of as public awareness of this has risen, we've seen a comparable spate of sort of basically generally communication privacy tools. Stuff like silent circle, whisper systems is actually really good if you don't have signal installed in your iPhone or most of you have probably heard of TOR, which but this is actually very confusing to generally the lay person or even the not particularly security interested technical person because you don't really know what you're trying to protect yourself against or what type of, -- I mean it's not -- you know, what's a method methodical way of thinking about these? It's all we know that there are powerful people that want to do bad things and software developers that might do stuff that I might do and making a lot of money doing it. So I thought I'd discuss threat modeling for these types of attackers, so this is, you this is a very scientific taxonomy of threat that I came up with on a bar napkin one time and I will now present it to you in slide form. So most of you guys have probably heard of Alice and Bob and Eve, right? Hands? Yeah, great, so anyone who's done five minutes of reading about cryptography learn about this, right? And this is, you know, Alice wants to have a conversation with Bob sends an e-mail to via the happy mail account, and then, you know, they have even they might even have an HTTPS login to this e-mail service and eve is the malicious eavesdrop dropper. Now for the purpose of this argument, let's assume that the cost of eve is zero. Now, setup costs for eve might be billions of dollars, right, because eve is fiber taps and internet exchanges, eve is, you know, rooms in AT & T, eve is alligator clips on wires, if you've seen the life of others, eve is the, you know, state agent listening to and doggedly transcribing phone calls, but we assume that eve is omnipresent and the cost of using Eve to listen to you is very low. Sometimes Eve is done at scale. I was, working at Google when this happened. The GCHQ was harvesting Googles' data. And so what they'd done is the staked tapping Google's leased lines and they had this very hilarious slide where they had SSL added and removed here. If you worked at Google at the time it looked like this. I thought they didn't understand the kind of huddle ACTH Barr RPC very well. So the cost of eve is zero. I mean it's cheap for them. Eve is pretty easy to defeat. You can kind of you can defeat Eve through the use of basic encryption software. Eve has pricier meaner older sister that we're going to call Mallory. Now, Mallory is your malicious active attacker. This diagram was drawn for me by willowbloo.
   So hacking team actually created this platform which they called a network injector which is basically a mechanism for performing man in the middle attacks at scale which you can do if you own the wires. It plugs into a radio server, you just look up someone's name it tells you their IP address straight away, you isolate their traffic stream, look for like an HTTP node of a binary or something like that and you just change it and you just sort of melt that binary together with your implant, I can mature it doesn't mess with icon and when someone runs it on download it will stick the it will run the original and you'll get your installer or whatever. Another way that they were actually doing it, because I mean waiting for people to download software might be a drag so they would actually inject things into traffic streams and one of the things they would do is inject things into YouTube streams because the actual stream looked like it was https the video would actually plain clear text. So here is your bank of cats at the other end, and the malicious attacker would wait for the clear text stream and then it would tell someone that they needed to update your flash player. Which absolutely every suggestion to update your flash player on the internet is malicious and so Google actually fixed this. It was kind of one of these things as a generally known vulnerability in the state of the internet, right? This is a problem with how we decided to do transport in the beginning but of course if you're running a large service and you discover that people are actively exploiting this to attack your users, you kind of have to fix it and Google actually did. Now I mean this is just an example of what a user gets, right? You get the bogus flash player. Now, how much does this sort of rig cost? 874 Swiss francs. So let's say a million dollars. If I bought this million dollars I'm not sure what I would do with this rack. I would inject the hell out of people that used my GIS wireless. So I mean targeted teams are also, there's been a lot of discussion on Chinese government hacking, this is also Mallory. This is actually a slide from an NSS presentation which I thought was a little bit underhanded. Turned out that the NSA was hoovering up Microsoft crashes. This slide was made by the NSA it self says this information may be intercepted by a foreign SIGINT. System. So Mallory costs something, right, because someone's got to write the software. Frequently a team of people if you're doing this efficiently you actually care a lot about the stability of your code. Right, like implants generally hook and are very low level in the operating system you need to not be crashing in blue screen all the time. If people start getting you know, core dumps and blue screens and that sort of thing, then this isn't very good and in fact as I said before, if a target is interesting it's likely to be targeted than more than one people so maybe you want your back door to be so stable that it's also run by so this is actually a really difficult problem when you think about it so you have a team of exceptionally skilled low level engineers. So I mean this costs money. Right and you know in a lot of places this also costs legal approvals. You know, like, I mean these lawyers, who I mean the Phiser courts, I want to hack this company, this let's have a look, intelligence, free Netflix, so you know it costs some money. Now if for some reason Mallory doesn't work. Mallory is cheaper than human intelligence and a lot more deniable. But then you actually need this and not George Clooney or Brad Pitt, but basically what I mean is an ops team someone that's going to gain physical access and steal things. It might look more like this. But this is very effective if you want to get intelligence, you know, people cut through glass I'm actually not on expert on this end of things, but it's sort of the human, the physical operation, now, this costs money, because it's people. So you have people highly trained enough to do this well and reliably obviously costs a lot of money to train them. There's a finite resource and there's a military chain of command or whatever. These people expect to be paid and they don't scale. But basically when people talk about raising the cost of surveillance, which comes up a lot in the sort of modern narrative what you want to do is you want to turn even to Mallory and turn Mallory into a burglar, now, I didn't say this, a reasonably smart friend of mine did and I ended up thinking, I was like, well, sure, I mean the burglar is kind of expensive or the special ops team and that kind of thing, but there's actually someone that comes after this, and it's Jack Bauer, now I'm not -- I've never actually watched 24, but Jack Bauer seems like a really unpleasant guy from what I can glean. He basically tortures people for like five seasons, he just ties people to chairs and just slaps them repeatedly, so Jack Bauer is kind of my by-line for a torture or I guess the industry term for this is rubber hose cryptography, right? You extract key materials or other sensitive information from someone through use of rubber hose and this is very expensive. Well, I mean it's very expensive because you're not really supposed to do it. I mean in order to do this institutionally, you need a black site, maybe something in Abu Graib perhaps, also if you're found out doing this, it costs you political cachet, which is more than money because it -P means that the president of a country has to stand up on television and say yeah, we tortured some folks we're really sorry and so on and so the to, and that's something that politicians really don't like doing, but this is kind of a useful scale to think about when we actually talk about in terms of surveillance. It's a kind of um -- I mean if we want to talk about a cost benefit analysis, right, but these are the -- these are the sort of the types of actors, now let's actually talk about the players in the real world that we get, right? And so this is the GCHQ. I chose to use this picture that Banksy drew in London. This is the illustration that the EFF uses the eagle withholding the phone lines in its talons but functionally these are the high end attackers, right? So we've got US, UK, the Israel, China, Russia France. the joke he made was what is it advanced Russia, persistent China, threat Israel so there's kind of a lot of discussion of this type of thing in the security scene and this is, you know, these people, they -- you know, they make artisanal small batch locally made homegrown malware because you've got a lot of developers, right? You can have a team of 30, 40 people writing this stuff over 10 years and you can have a team of 100 operators and there is a lot of resource, there's a lot of universities, there's a lot of skilled developers, there's a lot of money, then you've sort of got this next tier of countries.  And what they do is they buy stuff like Hacking Team software like Finfisher and they don't necessarily have the depths to do the homegrown bespoke, because again, remember, you know, what I talked about low-level developers, you actually do need expertise for this. And so there's a commercial market and these vendors, they sell to law enforcement, intelligence agencies and they kind of probably shouldn't but sometimes they sell to third party security companies and this is the tier of actors that I describe pass the pay for tools tier and then down another tier you kind of get cyber mercenaries and we have actually seen a rise of this type of thing a over the last few years. There was actually someone on line offering root@MYSQL on some forum for like $500. Leo impact is another one and these guys will do sort of bespoke jobs for you and so they sort of position themselves as investigators in the form of ethical hackers and so you know, them' break into opposing legal counsel during court cases and steal their data and let you know what they're doing and all this type of thing. They're for countries that don't have this dedicated program but it's worth paying these people for one-off jobs and then of course there's cyber crime. Sometimes these people are very good they're definitely institutional and organized. There is more money in ad fraud than there is in anything else right now and this is the gotta get paid contingent. They're not interested in particular targets they're just interested in overall the amount of money they make and so the equation for all of these people is the same, right, which is the attacker resources versus cost versus how much a target actually is worth to you. And then there's of course the one type of attacker which I haven't mentioned yet. Which is the Black Hat, the hacktivist, the personally motivated, and I don't -- it's difficult playing these types of attackers, because it's not necessarily sort of the logic doesn't really exist there in the same way. So with the other ones if there's a like cost is too high to acquire this target we're going to ditch, with this one, you know, never underestimate someone who is cash-poor but time-rich and when will they stop? We don't know this person might be pissed forever. But for all reasonable sort of attackers, you know, what I call methodical or professional or whatever, there's a kind of like, you know, this business stock diagram that I have used here, you know, efficiency, quality, cost, it's the same type of thing when you're making standard business decisions and they probably have meetings that work in exactly the same way, there's a project manager, OK, list of targets this week, requisition, you know, blah, blah, blah and you know, spying now means that you sit in an office with multicolored bean bags and you have M and M things and smoothie and massagers on site. So these kind of blended threat categories. This isn't discreet as I said, for instance, you know, as I said human was more expensive but in some cases what is this? This a replenishing a mini bar or is this an evil maid attack on your hotel room? This was actually my hotel room. So I mean also it's not a discrete category of enemies, right? Because in some cases for instance, say I'm protecting my journalists who are writing a story about national security, FBI probably wouldn't like me to know what I'm doing, however, Charlie Hebdo style attacks where 8 journalists are killed, FBI is a good friend. but the concern is the same for both sides. It's cheaper than insider threat or human intelligence and that type of thing. It's all about sort of leveraging what you can control and for both attackers and contenders, if you're running a company, what's the most cost-effective way to either compromising that data or protecting that data, you know, just like we talked about before, or I didn't talk about, but in the earlier talk, light, complexity and cost isn't always negative if it's protecting data but of course you want to balance this with what you get out of it. So this is one slide, not fit all problem. So I've spent a lot of time dealing with people that have asked me questions about this type of thing so that's kind of the end of the taxonomy thing and this is the kind of the human problem here. Saying to people like what can I do to protect myself? Well, against what and what are you trying to protect is sort of how can I tell if I'm compromised? And I'm like, well, you know, again, by who and what do you think is compromised and you sort of get this like hey I'd like you to look at my random device because I'm kind of a politically interested person and I think that I'm really important and probably a target of nation state surveillance and after spending a while sort of trying to answer these questions really earnestly, I discovered that what a lot of people actually wanted to hear was oh, there's this app called Morgan's total security that works for your iPhone, you just I stall it and everything is sweet. Because what they don't want to hear is like, hm, had how do you really protect yourself and it's like well, you should probably hire a top-flight security team, give them invasive access to all of your data and communications so they can monitor everything you do in real life because if you had pa physical threat that's what you'd do. You'd hire a bunch of burly ex special forces people to stand around in your house and they'd stand there and look tough and they'd also act as a deterrent and shoot people if they got close but it's really invasive and annoying, right? Same problem. But this is what people actually want, right? Which kind of makes me a little uncharitable, shall we say? And as I said, security engineer, no actually not that great with humans, spent a lot of time actually trying to get better, but it's a learning curve. And this is complicated, right so we hit the whole complicated stuff is indistinguishable from magic, which is fair.
   So the analogy that ended up using with people frequently is like well, you know, what happens if you think that you have some sort of bizarre disease, right, you go to a doctor, and say, doc, I think I have, you know, whooping chills or something, and you know, the doctor says, like, well, why do you think this, are you symptomatic and you say no, and he's like, hm, well, have you been anywhere strange recently? Like, well, no, well like, you're probably fine then. Well, I don't feel fine, like I have money, I would like you to do a battery of invasive tests on me. Like, well, I can okay, and he this so they take a hospital of your blood and urine and spit and a piece of your arm or something and then this gets sent off to a lab where a really educated lab tech will take a long time using expensive tools to look at this stuff and then send back these results and you'll never actually meet this lab tech, right, and the results take an indeterminate amount of time to happen and you can't really read them when they show up and then the doctor tells you that you're fine. And I mean this is actually kind of what actually happens. This is an analogy that people actually understand when they come up to me and say hey, how do I figure out how my computer is compromised. Well I'd probably take an image of your memory and I'd try to see if your allocation tables have been modified in some way, etc., etc., which of course again, you know, actually, people want the app. They don't want to hear a discussion about how the lab tests happen. Now, yeah, so I mean I've been spending a while thinking about this problem and you know, like I don't actually know about this assertion. That may not be true because that's that's no the what I'm expert at but I'm going to assume that we can't design better humans right now or humans that are more resilience to surveillance or any of those kind of things. What we and by we I think this crowd can can do is design more resilient systems to this crowd and I say this crowd. There are actually some actually like really secure systems, it's just nobody uses them.
   And so it sort of goes back to what I was talking about before, which was coercion resistant design, right, and so the axiom that I sort of produce here and when I first start evidence thinking about this I sounded like one of the paranoid people that puts their phone in the fridge, but you know, I think -- I think, you know, sort of general understanding of this landscape is better these days and I've spent the last 18 months, if you remember what my actual day job is, working on systems for handling sensitive data, storing it, transporting it, and sort of dealing with its you know, daily engagement and so I've been thinking about coercion resistant design again a lot, and you know, it is possibly obvious to some of you why this applies to my day job, you but you might be thinking, well, why does this apply to any of you so my assertion actually is that as your service app, website, whatever, increases in popularity, the likelihood that you will eventually be forced to cores your security model becomes definite, right? And I say this because you're creating the new WhatsApp. You're creating Netflix, Fastly or Wikipedia or anything like that, right? All of that data is appealing.  Literally all of it. I want to be able to see what Wikipedia articles people are reading, I definitely want to see what people are messaging each here. I have know why how many drug deals taken place over WhatsApp but probably a lot. There's really a large political issue about this right now, there's actually been a lot of legal demands to alter systems and provide key materials and that sort of thing for a lot of really large players. And I mean this goes back a long way, actually. Like this hasn't happened in a vacuum. This is sort of like the first crypto wars which goes back to the cipher punk thing when I was in New Zealand. Which is when I first started thinking about this. But I mean if we and then we won the first crypto wars, so a, Microsoft, right, when they first launched disk encryption. Lava bit was Edward Snowden's e-mail provider, Skype is a really interesting one. Because initially the way they designed it, they said, look, there's Skype was this encrypted peer to peer protocol and they were like we wouldn't know how to tap this if we tried. There was an internal NSA project called project chess becauseically to force Skype to be tappable. Of course now that it's owned by Microsoft it is very much so. Any data is interesting. I love this one. World of spy craft. So the NSA and CIA spied on line games. If you have users and your service is popular, then you have data that is interesting to people. Now, I mean I'm focusing a lot on the state here because there's -- I mean there's sort of documentation and history around this. However, you know, when I talk about coercion, I actually talk about anyone that's likely to coerce the data out of you. But there's a lot of people who don't really care about legitimacy, organized crime and so on and so forth,  this would also be interested in getting data that's pertinent to them out of people. And at the moment the FBI in a big fight with Google and Apple and anyone else in their view that is actually trying to provide robust privacy protection to their customers and the legal aspects of this actually become very interesting because while the FBI thinks they represent the interests of government, that's not especially entirely true because we're the government, too, and we think this is a really terrible idea like we don't people to engineer deliberate bad systems.
   >> And while I've been kind of aware of while I'm sort of doing this rant that I might sound like a crazy person because I'm like oh, my God you should really engineer systems in a way that assume governmental coercion, etc., etc., we actually have been building systems that we think are important like this for some time. For instance the DNS design that is DNSDec it actually already exists. That's a whole bunch of people from a whole bunch of different countries and that's because we decided DNS was really core and really important. All that was in the age when the only thing that we thought was important was the service. As it's been pointed out through this conference and Alex said before, we're kind of starting to run the world now, so as everything moves online, I think it's actually more and more important that we design systems with the duty to our users in mind. And I'd like to finish -- oh, so, as I mentioned, I don't think this is actually that different from the way a lot of people think right now. I mean it's kind of like designing for failure only with a little more dystopian future, you know, you guys have read cyberpunk novels. I'd like to actually finish though, by returning to that analogy, right, like currently the way security is applied is actual likely western medicine. If you think there's something wrong you can consult people. This works great financially for my industry but I think sort of less well for security systems design. I mean and there are interesting sort of forays into approaches some of which have been talked about in this conference like Rust and things like this, but I think it will actually come from the people who are designing systems and creating them, rather than the people who are auditing systems. There was a keynote speaker who didn't get to be here, Kathy Sierra she also wasn't at the EFF pipe year awards on Thursday night, where I was.  But she sent this nice note which is ... "no outside help is coming ... ... ... ..." 
   So thank you, that's me.
   [applause]
   >> I think I'm like well over time, so I don't have time for questions.
   >> Alex: Thanks so much. That was great, thanks. So we were at the end of the day, and the venue staff has asked me if we could move expeditiously towards the street, they would appreciate it. So that they can go home. But thank you all for being here. It was wonderful, it was a great year.
   [applause]
   [cheers]
   And we will be back here sept 15th through 17th, 2016, so I hope I'll see some of you here. Come on back. ... 
